# Metrics æå–å’Œåˆ†æå·¥å…·

## ğŸ“‹ æ¦‚è¿°

æœ¬ç›®å½•åŒ…å«ç”¨äºæå–å’Œåˆ†ææµ‹è¯•æ¡ˆä¾‹æŒ‡æ ‡æ•°æ®çš„å·¥å…·é›†ï¼Œèƒ½å¤Ÿæ­£ç¡®æå–æ¯ä¸ªtest caseå¯¹åº”çš„metricsDataé‡Œé¢çš„scoreã€reasonç­‰å­—æ®µã€‚

## ğŸ› ï¸ å·¥å…·åˆ—è¡¨

### 1. `extract_metrics_corrected.py` - å®Œæ•´æ•°æ®æå–å™¨
**åŠŸèƒ½**: ä»æµ‹è¯•è¿è¡Œæ–‡ä»¶ä¸­æå–å®Œæ•´çš„metricsæ•°æ®ï¼ŒåŒ…æ‹¬æ¯ä¸ªæŒ‡æ ‡çš„scoreã€reasonã€successç­‰æ‰€æœ‰å­—æ®µã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
# åŸºç¡€ä½¿ç”¨
python extract_metrics_corrected.py

# æŒ‡å®šè¾“å…¥æ–‡ä»¶å’Œè¾“å‡ºå‰ç¼€
python extract_metrics_corrected.py --input .deepeval/.latest_test_run.json --output my_analysis

# æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
python extract_metrics_corrected.py --show-details
```

**è¾“å‡ºæ–‡ä»¶**:
- `*_detailed.csv`: åŒ…å«æ‰€æœ‰å­—æ®µçš„è¯¦ç»†æ•°æ®
- `*_metrics_only.csv`: ä»…åŒ…å«æŒ‡æ ‡åˆ†æ•°å’ŒæˆåŠŸçŠ¶æ€çš„ç®€åŒ–è¡¨æ ¼
- `*_summary.json`: ç»Ÿè®¡æ±‡æ€»ä¿¡æ¯

### 2. `view_case_metrics.py` - äº¤äº’å¼æŸ¥çœ‹å™¨
**åŠŸèƒ½**: æä¾›å¤šç§æ–¹å¼æŸ¥çœ‹å’Œåˆ†ææµ‹è¯•æ¡ˆä¾‹çš„æŒ‡æ ‡æ•°æ®ã€‚

**ä½¿ç”¨æ–¹æ³•**:
```bash
# æŸ¥çœ‹ç‰¹å®šæ¡ˆä¾‹çš„è¯¦ç»†ä¿¡æ¯
python view_case_metrics.py --case 0 --reasons

# æ˜¾ç¤ºæ‰€æœ‰æ¡ˆä¾‹çš„å¯¹æ¯”è¡¨æ ¼
python view_case_metrics.py --table --output comparison.csv

# æ˜¾ç¤ºç»Ÿè®¡æ±‡æ€»
python view_case_metrics.py --stats

# æŸ¥çœ‹å‰å‡ ä¸ªæ¡ˆä¾‹ï¼ˆä¸æ˜¾ç¤ºåŸå› ï¼‰
python view_case_metrics.py
```

## ğŸ“Š æ•°æ®ç»“æ„è¯´æ˜

### MetricsData ç»“æ„
æ¯ä¸ªæµ‹è¯•æ¡ˆä¾‹çš„ `metricsData` æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«å¤šä¸ªæŒ‡æ ‡å¯¹è±¡ï¼š

```json
{
  "metricsData": [
    {
      "name": "Answer Correctness",
      "score": 0.285,
      "reason": "è¯¦ç»†çš„è¯„ä¼°åŸå› ...",
      "success": false,
      "threshold": 0.5,
      "strictMode": false,
      "evaluationModel": "Custom Volce OpenAI Model",
      "verboseLogs": "è¯¦ç»†æ—¥å¿—..."
    }
  ]
}
```

### æå–çš„å­—æ®µ
å¯¹äºæ¯ä¸ªæŒ‡æ ‡ï¼Œå·¥å…·ä¼šæå–ä»¥ä¸‹å­—æ®µï¼š
- `{metric_name}_score`: æŒ‡æ ‡åˆ†æ•°
- `{metric_name}_reason`: è¯„ä¼°åŸå› 
- `{metric_name}_success`: æ˜¯å¦é€šè¿‡
- `{metric_name}_threshold`: é˜ˆå€¼
- `{metric_name}_strict_mode`: ä¸¥æ ¼æ¨¡å¼
- `{metric_name}_evaluation_model`: è¯„ä¼°æ¨¡å‹

## ğŸ“ˆ å½“å‰æŒ‡æ ‡ç±»å‹

æ ¹æ®æµ‹è¯•æ•°æ®ï¼Œç³»ç»ŸåŒ…å«ä»¥ä¸‹4ç§æŒ‡æ ‡ï¼š

1. **Argument Correctness** (å‚æ•°æ­£ç¡®æ€§)
   - å¹³å‡åˆ†æ•°: 0.992
   - é€šè¿‡ç‡: 98.8%
   - è¯„ä¼°å·¥å…·è°ƒç”¨å‚æ•°çš„æ­£ç¡®æ€§

2. **Contextual Recall** (ä¸Šä¸‹æ–‡å¬å›)
   - å¹³å‡åˆ†æ•°: 0.711
   - é€šè¿‡ç‡: 71.1%
   - è¯„ä¼°æ£€ç´¢ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§

3. **Tool Correctness** (å·¥å…·æ­£ç¡®æ€§)
   - å¹³å‡åˆ†æ•°: 0.627
   - é€šè¿‡ç‡: 62.7%
   - è¯„ä¼°å·¥å…·è°ƒç”¨çš„æ­£ç¡®æ€§

4. **Answer Correctness** (ç­”æ¡ˆæ­£ç¡®æ€§)
   - å¹³å‡åˆ†æ•°: 0.285
   - é€šè¿‡ç‡: 18.1%
   - è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### å¿«é€ŸæŸ¥çœ‹æ•´ä½“æƒ…å†µ
```bash
python view_case_metrics.py --stats
```

### åˆ†æç‰¹å®šå¤±è´¥æ¡ˆä¾‹
```bash
# æŸ¥çœ‹æ¡ˆä¾‹0çš„è¯¦ç»†ä¿¡æ¯
python view_case_metrics.py --case 0 --reasons
```

### ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
```bash
# æå–æ‰€æœ‰æ•°æ®å¹¶ç”Ÿæˆå¤šç§æ ¼å¼çš„æŠ¥å‘Š
python extract_metrics_corrected.py --show-details --output full_analysis

# ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
python view_case_metrics.py --table --output metrics_comparison.csv
```

### æ‰¹é‡åˆ†æ
```bash
# æå–è¯¦ç»†æ•°æ®
python extract_metrics_corrected.py --input .deepeval/.latest_test_run.json --output batch_analysis

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python view_case_metrics.py --stats --input .deepeval/.latest_test_run.json
```

## ğŸ“‹ è¾“å‡ºæ ¼å¼è¯´æ˜

### CSVæ ¼å¼ (è¯¦ç»†æ•°æ®)
åŒ…å«æ¯ä¸ªæµ‹è¯•æ¡ˆä¾‹çš„å®Œæ•´ä¿¡æ¯ï¼š
- åŸºç¡€ä¿¡æ¯: case_id, case_name, input, actual_output, expected_output
- æ‰§è¡Œä¿¡æ¯: success, run_duration
- æŒ‡æ ‡æ•°æ®: æ¯ä¸ªæŒ‡æ ‡çš„score, reason, success, thresholdç­‰

### CSVæ ¼å¼ (ä»…æŒ‡æ ‡)
ç®€åŒ–çš„æŒ‡æ ‡å¯¹æ¯”è¡¨æ ¼ï¼š
- æ¡ˆä¾‹åŸºç¡€ä¿¡æ¯
- æ¯ä¸ªæŒ‡æ ‡çš„åˆ†æ•°å’Œé€šè¿‡çŠ¶æ€
- ä¾¿äºExcelç­‰å·¥å…·è¿›ä¸€æ­¥åˆ†æ

### JSONæ ¼å¼ (ç»Ÿè®¡æ±‡æ€»)
åŒ…å«æ•´ä½“ç»Ÿè®¡ä¿¡æ¯ï¼š
- æ€»æ¡ˆä¾‹æ•°å’ŒæˆåŠŸç‡
- æ¯ä¸ªæŒ‡æ ‡çš„å¹³å‡åˆ†æ•°ã€åˆ†æ•°èŒƒå›´ã€é€šè¿‡ç‡ç­‰

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®ç»“æ„**: metricsDataæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œä¸æ˜¯å­—å…¸
2. **æŒ‡æ ‡åç§°**: ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºåˆæ³•çš„åˆ—åï¼ˆå°å†™+ä¸‹åˆ’çº¿ï¼‰
3. **æ–‡ä»¶è·¯å¾„**: é»˜è®¤è¯»å– `.deepeval/.latest_test_run.json`
4. **ç¼–ç æ ¼å¼**: æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ä½¿ç”¨UTF-8ç¼–ç 

## ğŸ”„ ç‰ˆæœ¬å†å²

- **v1.1** (2025-09-24): ä¿®æ­£äº†metricsæ•°æ®æå–é€»è¾‘ï¼Œæ­£ç¡®å¤„ç†metricsDataåˆ—è¡¨ç»“æ„
- **v1.0** (2025-09-24): åˆå§‹ç‰ˆæœ¬ï¼Œå­˜åœ¨æ•°æ®ç»“æ„ç†è§£é”™è¯¯

## ğŸš€ æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒå¤šä¸ªæµ‹è¯•è¿è¡Œæ–‡ä»¶çš„å¯¹æ¯”åˆ†æ
- [ ] æ·»åŠ å¯è§†åŒ–å›¾è¡¨ç”ŸæˆåŠŸèƒ½
- [ ] å®ç°æŒ‡æ ‡è¶‹åŠ¿åˆ†æ
- [ ] æ”¯æŒè‡ªå®šä¹‰æŒ‡æ ‡é˜ˆå€¼è®¾ç½®